# Paper Understanding
- [Visualizing and Understanding Convolutional Networks](https://arxiv.org/pdf/1311.2901.pdf)
## Introduction
- We introduce ***a visualization technique that reveals the input stimuli that excite individual feature maps at any layer in the model.*** It also allows us to observe the evolution of features during training and to diagnose potential problems with the model. The visualization technique we propose uses a multi-layered Deconvolutional Network (deconvnet), as proposed by [1] to project the feature activations back to the input pixel space.
- We also perform a sensitivity analysis of the classifier output by occluding portions of the input image, revealing which parts of the scene are important for classification.
## Methodology
- Figure 1
    - <img src="https://user-images.githubusercontent.com/105417680/229678910-16b9d2db-68fa-4f0e-8ddf-31730de8766a.png" width="600">
    - We present a novel way to map these activities back to the input pixel space, ***showing what input pattern originally caused a given activation in the feature maps.*** We perform this mapping with a Deconvolutional Network (deconvnet) [1]. A deconvnet can be thought of as a convnet model that uses the same components (filtering, pooling) but in reverse, so instead of mapping pixels to features does the opposite. In [1], deconvnets were proposed as a way of performing unsupervised learning.
    - To examine a convnet, a deconvnet is attached to each of its layers, providing a continuous path back to image pixels. ***To start, an input image is presented to the convnet and features computed throughout the layers. To examine a given convnet activation, we set all other activations in the layer to zero and pass the feature maps as input to the attached deconvnet layer.*** Then we successively (i) unpool, (ii) rectify and (iii) filter to reconstruct the activity in the layer beneath that gave rise to the chosen activation. This is then repeated until input pixel space is reached.
    - Unpooling:
        - ***In the convnet, the max pooling operation is non-invertible, however we can obtain an ap- proximate inverse by recording the locations of the maxima within each pooling region in a set of switch variables. In the deconvnet, the unpooling operation uses these switches to place the reconstructions from the layer above into appropriate locations, preserving the structure of the stimulus.***
        - Projecting down from higher layers uses the switch settings generated by the max pooling in the convnet on the way up. As these switch settings are peculiar to a given input image, ***the reconstruction obtained from a single activation thus resembles a small piece of the original input image, with structures weighted according to their contribution toward to the feature activation. Since the model is trained discriminatively, they implicitly show which parts of the input image are discriminative.***
    - Rectification: The convnet uses relu non-linearities, which rectify the feature maps thus ensuring the feature maps are always positive. To obtain valid feature reconstructions at each layer (which also should be positive), we pass the reconstructed signal through a relu non-linearity.
    - Filtering: The convnet uses learned filters to convolve the feature maps from the previous layer. To invert this, the deconvnet uses transposed versions of the same filters.
## References
- [1] [Adaptive Deconvolutional Networks for Mid and High Level Feature Learning]
- [2] [ImageNet Classification with Deep Convolutional Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)